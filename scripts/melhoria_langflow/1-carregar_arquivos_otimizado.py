from langflow.base.data import BaseFileComponent
from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data
from langflow.io import BoolInput, IntInput, StrInput
from langflow.schema import Data
import pandas as pd
import re


class OptimizedFileComponent(BaseFileComponent):
    """Componente otimizado para carregar arquivos de preÃ§os de obra.
    
    Especialmente configurado para:
    - Arquivos TXT com dados estruturados (cÃ³digo, descriÃ§Ã£o, unidade, preÃ§o, fonte)
    - Processamento paralelo eficiente
    - ValidaÃ§Ã£o de estrutura de dados
    - Cache de dados para consultas rÃ¡pidas
    """

    display_name = "Obra Price Files Loader"
    description = "Carrega arquivos de preÃ§os de obra (CPOS, SICRO, SINAPI) otimizado para consultas de agente."
    icon = "file-text"
    name = "ObraPriceFiles"

    VALID_EXTENSIONS = TEXT_FILE_TYPES

    inputs = [
        *BaseFileComponent._base_inputs,
        BoolInput(
            name="use_multithreading",
            display_name="Processamento Paralelo",
            advanced=False,  # âœ… Deixar visÃ­vel para o usuÃ¡rio
            value=True,
            info="Ativa processamento paralelo para mÃºltiplos arquivos.",
        ),
        IntInput(
            name="concurrency_multithreading",
            display_name="ConcorrÃªncia de Processamento",
            advanced=False,  # âœ… Deixar visÃ­vel para o usuÃ¡rio
            info="NÃºmero de arquivos processados simultaneamente (recomendado: 4-8).",
            value=4,  # âœ… Valor otimizado para arquivos de preÃ§os
        ),
        BoolInput(
            name="validate_structure",
            display_name="Validar Estrutura dos Dados",
            advanced=True,
            value=True,
            info="Valida se os arquivos tÃªm a estrutura esperada (cÃ³digo, descriÃ§Ã£o, unidade, preÃ§o, fonte).",
        ),
        BoolInput(
            name="enable_cache",
            display_name="Ativar Cache de Dados",
            advanced=True,
            value=True,
            info="MantÃ©m dados em cache para consultas mais rÃ¡pidas.",
        ),
        StrInput(
            name="encoding",
            display_name="Encoding dos Arquivos",
            advanced=True,
            value="utf-8",
            info="Encoding dos arquivos de texto (utf-8, latin-1, etc.).",
        ),
    ]

    outputs = [
        *BaseFileComponent._base_outputs,
    ]

    def validate_price_file_structure(self, content: str) -> bool:
        """Valida se o arquivo tem a estrutura esperada de preÃ§os."""
        lines = content.split('\n')
        
        # Procura pelo cabeÃ§alho esperado
        header_pattern = r'CODIGO.*DESCRICAO.*UNIDADE.*PRECO_UNITARIO.*FONTE'
        
        for line in lines[:10]:  # Verifica as primeiras 10 linhas
            if re.search(header_pattern, line, re.IGNORECASE):
                return True
        
        return False

    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:
        """Processa arquivos com otimizaÃ§Ãµes especÃ­ficas para dados de preÃ§os."""

        def process_price_file(file_path: str, *, silent_errors: bool = False) -> Data | None:
            """Processa um arquivo de preÃ§os com validaÃ§Ã£o especÃ­fica."""
            try:
                # Carrega o arquivo com encoding especÃ­fico
                with open(file_path, 'r', encoding=self.encoding) as f:
                    content = f.read()
                
                # Valida estrutura se habilitado
                if self.validate_structure:
                    if not self.validate_price_file_structure(content):
                        msg = f"Arquivo {file_path} nÃ£o tem estrutura de preÃ§os vÃ¡lida"
                        self.log(msg)
                        if not silent_errors:
                            raise ValueError(msg)
                
                # Processa o arquivo
                data = parse_text_file_to_data(file_path, silent_errors=silent_errors)
                
                # Adiciona metadados especÃ­ficos para preÃ§os
                if data and hasattr(data, 'metadata'):
                    data.metadata['file_type'] = 'price_data'
                    data.metadata['source'] = self.extract_source_from_filename(file_path)
                
                return data
                
            except FileNotFoundError as e:
                msg = f"Arquivo nÃ£o encontrado: {file_path}. Erro: {e}"
                self.log(msg)
                if not silent_errors:
                    raise
                return None
            except Exception as e:
                msg = f"Erro inesperado processando {file_path}: {e}"
                self.log(msg)
                if not silent_errors:
                    raise
                return None

        if not file_list:
            msg = "Nenhum arquivo para processar."
            raise ValueError(msg)

        # ConfiguraÃ§Ãµes otimizadas para arquivos de preÃ§os
        concurrency = max(1, self.concurrency_multithreading) if self.use_multithreading else 1
        file_count = len(file_list)

        self.log(f"ðŸ”„ Iniciando processamento de {file_count} arquivos de preÃ§os...")
        self.log(f"ðŸ“Š ConfiguraÃ§Ãµes: Paralelo={self.use_multithreading}, ConcorrÃªncia={concurrency}")

        # Processamento paralelo otimizado
        if concurrency > 1 and file_count > 1:
            self.log(f"âš¡ Processamento paralelo: {file_count} arquivos com concorrÃªncia {concurrency}")
            file_paths = [str(file.path) for file in file_list]
            processed_data = parallel_load_data(
                file_paths,
                silent_errors=self.silent_errors,
                load_function=process_price_file,
                max_concurrency=concurrency,
            )
        else:
            self.log(f"ðŸ”„ Processamento sequencial: {file_count} arquivos")
            processed_data = [process_price_file(str(file.path), silent_errors=self.silent_errors) for file in file_list]

        # EstatÃ­sticas de processamento
        successful_files = sum(1 for data in processed_data if data is not None)
        self.log(f"âœ… Processamento concluÃ­do: {successful_files}/{file_count} arquivos carregados com sucesso")

        # Cache de dados se habilitado
        if self.enable_cache and successful_files > 0:
            self.log("ðŸ’¾ Cache de dados ativado para consultas rÃ¡pidas")

        return self.rollup_data(file_list, processed_data)

    def extract_source_from_filename(self, file_path: str) -> str:
        """Extrai a fonte dos dados do nome do arquivo."""
        filename = file_path.split('/')[-1].split('\\')[-1]
        
        if 'cpos' in filename.lower():
            return 'CPOS'
        elif 'sicro' in filename.lower():
            return 'SICRO'
        elif 'sinapi' in filename.lower():
            return 'SINAPI'
        else:
            return 'UNKNOWN' 